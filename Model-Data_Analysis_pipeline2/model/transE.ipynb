{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <span style=\"font-family: 'Playfair Display', serif; font-size: 24px; font-weight: bold;\">\n",
    "    Constructing a Knowledge Graph and Creating Embeddings for Price Group Prediction\n",
    "  </span>\n",
    "</div>\n",
    "\n",
    "___\n",
    "\n",
    "In this notebook, we focus on constructing a Knowledge Graph and generating embeddings for predicting price groups. The main steps include:\n",
    "\n",
    "- RDF Triplets: We have mapped the cleaned data to the RDF schema, and now we convert it into RDF triples (subject-predicate-object format).\n",
    "- Embedding Generation: Using the TransE model, we generate embeddings from the RDF triples to capture the relationships within the knowledge graph.\n",
    "- Model Training: The embeddings are used as input features to train a Multi-Layer Perceptron (MLP) model for price group prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchkge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "from torch.optim import Adam\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torchkge.models import TransEModel\n",
    "from torchkge.utils import MarginLoss, DataLoader\n",
    "from torchkge.data_structures import KnowledgeGraph\n",
    "from torchkge.sampling import BernoulliNegativeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph from TTL file\n",
    "g = Graph()\n",
    "g.parse(\"./../../data/explotation_zone/RDFGraph_Model_emb.ttl\", format=\"ttl\")\n",
    "\n",
    "# Extract triples in order to create the Knowledge graph\n",
    "print('Creating the triples...')\n",
    "triples = []\n",
    "for s, p, o in g:\n",
    "    triples.append((str(s), str(p), str(o)))\n",
    "\n",
    "directory = './../data/explotation_zone'  \n",
    "os.makedirs(directory, exist_ok=True)\n",
    "file_path = os.path.join(directory, 'RDFTriples.txt')\n",
    "\n",
    "# Save triples into a file\n",
    "with open(file_path, 'w') as f:\n",
    "    for triple in triples:\n",
    "        f.write(\"\\t\".join(triple) + \"\\n\")\n",
    "print('Done!')\n",
    "print()\n",
    "\n",
    "print('Creating the Knowledge graph...')\n",
    "# Convert into DataFrame and reorganize col to torchKGE format\n",
    "data = pd.DataFrame(triples, columns=['from', 'rel', 'to'])\n",
    "data = data[['from', 'to', 'rel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['rel'] == 'http://example.org/apartment/price_discretized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split between train and test:\n",
    "\n",
    "We split the data between train and test. Since we only want to predict the price of AirBNB apartments, only triples corresponding to the price relation are going to be evaluated. The model will still learn the relations between all nodes, including the nodes for which the later model will be predicting it's price group (although this relations has been erased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data['rel'] == 'http://example.org/apartment/price_discretized'].sample(frac = 0.2)\n",
    "train = data.drop(test.index)\n",
    "test_y = test['to']\n",
    "test_X = test.drop(columns = ['to'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the training graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_train = KnowledgeGraph(df=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be giving an output of 100 dimension embedding and will be trained with the parameters that can be seen in the code. The selected model is a TransE projection model. This selection has been made due to it's simplicity and therefore faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(kg_train, kg_val=None, emb_dim=100, n_epochs=1000, b_size=32768, lr=0.0004, margin=0.5):\n",
    "    \"\"\"\n",
    "    Trains an embedding model using torchKGE with a custom training loop.\n",
    "        :param kg_train: KnowledgeGraph, the training knowledge graph\n",
    "        :param kg_val: KnowledgeGraph, the validation knowledge graph (optional)\n",
    "        :param emb_dim: int, the dimension of the embeddings\n",
    "        :param n_epochs: int, the number of epochs to train\n",
    "        :param b_size: int, the batch size for training\n",
    "        :param lr: float, the learning rate\n",
    "        :param margin: float, the margin value for the TransE loss function\n",
    "    \"\"\"\n",
    "    # Define the embedding model\n",
    "    model = TransEModel(emb_dim, kg_train.n_ent, kg_train.n_rel, dissimilarity_type='L2')\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = MarginLoss(margin)\n",
    "\n",
    "    # Define the negative sampler and dataloader\n",
    "    sampler = BernoulliNegativeSampler(kg_train)\n",
    "    dataloader = DataLoader(kg_train, batch_size=b_size, use_cuda=device)\n",
    "\n",
    "    # Training loop\n",
    "    c = 0\n",
    "    iterator = tqdm(range(n_epochs), unit='epoch')\n",
    "    for epoch in iterator:\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            h, t, r = batch[0], batch[1], batch[2]\n",
    "            n_h, n_t = sampler.corrupt_batch(h, t, r)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            pos, neg = model(h, t, r, n_h, n_t)\n",
    "            loss = criterion(pos, neg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        iterator.set_description(\n",
    "            'Epoch {} | mean loss: {:.5f}'.format(epoch + 1, running_loss / len(dataloader)))\n",
    "        \n",
    "        c += 1\n",
    "\n",
    "        model.normalize_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(kg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is used as a mere checkpoint for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pkl', 'rb') as outp:\n",
    "    train = pickle.load(outp)\n",
    "\n",
    "with open('kg_train.pkl', 'rb') as outp:\n",
    "    kg_train = pickle.load(outp)\n",
    "\n",
    "with open('test_X.pkl', 'rb') as outp:\n",
    "    test_X = pickle.load(outp)\n",
    "\n",
    "with open('test_y.pkl', 'rb') as outp:\n",
    "    test_y = pickle.load(outp)\n",
    "\n",
    "with open('model.pkl', 'rb') as outp:\n",
    "    model = pickle.load(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"color: #01571B; background-color: #C8E5C6;\">\n",
    "\n",
    "Now, and using batch-processing to not overload the memory, we will get the embedding for each apartment in the training and test datasets separately. This will be later loaded in a torch tensor to train a future network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_list = []\n",
    "batch_size = 1000  # Adjust according to memory capacity\n",
    "\n",
    "filtered_items = train[train['rel'] == 'http://example.org/apartment/price_discretized']['from']\n",
    "\n",
    "for start in range(0, len(filtered_items), batch_size):\n",
    "    batch = filtered_items[start:start + batch_size]\n",
    "    batch_embeddings = []\n",
    "    for item in batch:\n",
    "        i = kg_train.ent2ix[item]\n",
    "        embedding = model.get_embeddings()[0][i]\n",
    "        if isinstance(embedding, np.ndarray):\n",
    "            batch_embeddings.append(embedding)\n",
    "        else:\n",
    "            batch_embeddings.append(np.array(embedding))  \n",
    "    \n",
    "    # Convert batch_embeddings to a NumPy array\n",
    "    batch_embeddings = np.stack(batch_embeddings)\n",
    "    \n",
    "    # Save intermediate results to disk\n",
    "    np.save(f'batch_{start}.npy', batch_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_list = []\n",
    "batch_size = 500  # Adjust according to memory capacity\n",
    "\n",
    "filtered_items = test_X['from']\n",
    "\n",
    "for start in range(0, len(filtered_items), batch_size):\n",
    "    batch = filtered_items[start:start + batch_size]\n",
    "    batch_embeddings = []\n",
    "    for item in batch:\n",
    "        i = kg_train.ent2ix[item]\n",
    "        embedding = model.get_embeddings()[0][i]\n",
    "        if isinstance(embedding, np.ndarray):\n",
    "            batch_embeddings.append(embedding)\n",
    "        else:\n",
    "            batch_embeddings.append(np.array(embedding)) \n",
    "    \n",
    "    # Convert batch_embeddings to a NumPy array\n",
    "    batch_embeddings = np.stack(batch_embeddings)\n",
    "    \n",
    "    # Save intermediate results to disk\n",
    "    np.save(f'./test_X/batch_{start}.npy', batch_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
